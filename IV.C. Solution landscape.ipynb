{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV.C. Solution landscape\n",
    "\n",
    "In this notebook, we explore the solution landscape of the map equation for the Jazz network.\n",
    "\n",
    "We run Infomap repeatedly and with different seeds to generate various partitions and cluster them to identify the partition clusters in the map equation's solution landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install or upgrade to to the latest version of Infomap, see https://mapequation.github.io/infomap/\n",
    "# pip install infomap / pip install --upgrade infomap\n",
    "import sys\n",
    "import infomap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from IPython.display import Image\n",
    "from scipy.interpolate import griddata\n",
    "import umap\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('text', usetex=True)\n",
    "sns.set(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update to the latest partition validation code (requires a gcc compiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#Clone partition-validation repo if it does not exist, otherwhise pull. Then compile.\n",
    "if [ ! -d \"partition-validation\" ] ; then\n",
    "    git clone https://github.com/mapequation/partition-validation.git\n",
    "else\n",
    "    git -C partition-validation pull\n",
    "fi\n",
    "make -C partition-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find communities with Infomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCommunities(networkName=\"data/jazz.net\", seed=1):\n",
    "    \"\"\"\n",
    "    Partition network with the Infomap algorithm.\n",
    "    Annotates nodes with 'community' id.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Find communities in {networkName} with Infomap...\",end=\"\")\n",
    "    im = infomap.Infomap(f\"-s {seed} --silent --two-level\")\n",
    "    im.read_file(networkName)\n",
    "    im.run()\n",
    "\n",
    "    print(f\"{im.num_top_modules} top modules with codelength: {im.codelength}\")\n",
    "    communityDict = {node.node_id: \":\".join(map(str, node.path[:-1]))\n",
    "                    for node in im.nodes}\n",
    "    \n",
    "    return im.codelength, [path for _, path in sorted(communityDict.items())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze partition robustness\n",
    "#### Definitions\n",
    "\n",
    "<dl>\n",
    "  <dt>Distance threshold</dt>\n",
    "  <dd>The maximum weighted Jaccard distance between a cluster center and any other partition in the same cluster.</dd>    \n",
    "    \n",
    "  <dt>Validation score</dt>\n",
    "  <dd>The fraction of validation partitions that fit into existing clusters.</dd>\n",
    "\n",
    "  <dt>Validation set size</dt>\n",
    "  <dd>The number of partitions hold out when measuring the validation score.</dd>       \n",
    "    \n",
    "  <dt>Accuracy</dt>\n",
    "  <dd>The threshold validation score for a complete solution landscape.</dd>\n",
    "</dl>\n",
    "\n",
    "#### Partition clustering algorithm\n",
    "\n",
    "1. Order all p network partitions from highest to lowest quality (from shortest to longest code length).\n",
    "1. Let the highest quality network partition form cluster center 1.\n",
    "1. Repeat until all network partitions have been clustered. Among the not yet clustered partitions, pick the one with the highest quality and assign it to the first of the m cluster centers it is closer to than the distance threshold. If no such cluster center exists, let it form cluster center m + 1.\n",
    "#### Solution landscape completeness algorithm\n",
    "\n",
    "To determine the sufficient number of searches for a solution that is good enough given the distance threshold and solution landscape accuracy, we\n",
    "\n",
    "1. Run Infomap twice the validation set size and add the new partitions to previously identified partitions.\n",
    "1. Randomly split all partitions into validation and training sets. Run the partition clustering algorithm on the training set and measure the validation score on the validation set. Resample a specified number of times for a better estimate.\n",
    "1. Repeat 1. and 2. until the validation score is higher than the specified accuracy.\n",
    "#### Guidelines\n",
    "\n",
    "Generally, a solution landscape with a small distance threshold and a high accuracy requires many partitions. Moreover, networks with a flat solution landscape, characterized by relatively small differences in code length for distant solutions, require more partitions than networks with a peaked solutions landscape, characterized by rather significant differences in code length for similar solutions.\n",
    "\n",
    "When exploring the solution landscape of a network, start with a relatively large distance threshold, say 0.3, for fast results. If the alluvial diagram shows that the solutions vary more than desired, reduce the distance threshold and repeat the analysis. Continue this procedure until the solution landscape is complete for an acceptable distance threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = 'data/jazz.net' #  A network with a peaked solutions landscape characterized by relatively large code length differences for similar solutions.\n",
    "accuracy = 0.9 # Requiring 90 percent of new solutions to fall into existing solclusters\n",
    "distance_threshold = 0.02 # A partition \n",
    "\n",
    "networkname = network.split(\"data/\", 1)\n",
    "networkname = networkname[len(networkname) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find 200 partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_df = pd.DataFrame() \n",
    "niter = 200\n",
    "for i in range(niter):\n",
    "    print(f\"Attempt {i+1}: \", end=\"\")\n",
    "    codelength, communities = findCommunities(network, i+123)\n",
    "    communities.insert(0, codelength)\n",
    "    partitions_df = pd.concat([partitions_df, pd.DataFrame(communities,columns = [str(i)])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify partition clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_threshold = 0.02\n",
    "partitions_df.sort_values(by=0, axis=1,inplace=True)\n",
    "codelengths = partitions_df.loc[0,:].to_numpy()\n",
    "partitions_df.drop(0, axis=0,inplace=False).to_csv(r'output/partitions.csv',index=False,header=False,sep=' ')\n",
    "!partition-validation/partition-validation -s 123 -t $distance_threshold output/partitions.csv output/partitions_clustering.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read partition clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only influde best maxclusters clusters\n",
    "maxclusters = 20\n",
    "partition_clusters_df = pd.read_csv('output/partitions_clustering.txt', delimiter=' ', comment='#')\n",
    "Nclusters = partition_clusters_df['ClusterId'].max()\n",
    "print(f\"Solution landscape contains {Nclusters} clusters with {partition_clusters_df.shape[0]} partitions.\")\n",
    "\n",
    "if Nclusters > maxclusters:\n",
    "    partition_clusters_df.drop(partition_clusters_df[partition_clusters_df.ClusterId > maxclusters].index, inplace=True)\n",
    "    Nclusters = partition_clusters_df['ClusterId'].max()\n",
    "    print(f\"Including only the best {Nclusters} clusters with {partition_clusters_df.shape[0]} partitions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify cluster sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterSizes = partition_clusters_df['ClusterId'].value_counts(sort=False)\n",
    "maxClusterSize = max(clusterSizes)\n",
    "solution_landscape_df = clusterSizes.to_frame('ClusterId').rename(columns={'ClusterId':'clustersize'})\n",
    "solution_landscape_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify cluster centers and code lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nclusters = partition_clusters_df['ClusterId'].max()\n",
    "clusterCenters = np.empty(Nclusters)\n",
    "\n",
    "for clusterId in range(1, Nclusters + 1):\n",
    "    clusterCenters[clusterId - 1] = partition_clusters_df['PartitionId'][(partition_clusters_df['ClusterId'] == clusterId).idxmax()]\n",
    "\n",
    "clusterCenters = clusterCenters.astype(int)\n",
    "clusterCenterCodelengths = codelengths[clusterCenters - 1]\n",
    "solution_landscape_df['partitionid'] = clusterCenters.tolist()\n",
    "solution_landscape_df['codelength'] = clusterCenterCodelengths.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify pairwise cluster center distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_df = pd.read_csv('output/partitions_clustering_distances.txt', delimiter=' ', comment='#')\n",
    "distances_df.drop(distances_df[(distances_df['ClusterId1'] > maxclusters) | (distances_df['ClusterId2'] > maxclusters)].index, inplace=True)\n",
    "distances_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create partition distance matrix and identify coordinates in 2D with [Uniform Manifold Approximation and Projection (UMAP)](https://github.com/lmcinnes/umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = distances_df.to_numpy()[:,0].astype(int) - 1\n",
    "col = distances_df.to_numpy()[:,1].astype(int) - 1\n",
    "distances = distances_df.to_numpy()[:,2]\n",
    "distance_matrix = np.zeros((Nclusters, Nclusters), dtype=distances.dtype)\n",
    "distance_matrix[row, col] = distances\n",
    "distance_matrix[col, row] = distances # Add transpose\n",
    "U = umap.UMAP(metric='precomputed', n_neighbors=Nclusters - 1, min_dist=distance_threshold)\n",
    "out = U.fit_transform(distance_matrix)\n",
    "solution_landscape_df['xcoord'] = out[:, 0]\n",
    "solution_landscape_df['ycoord'] = out[:, 1]\n",
    "solution_landscape_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize solution landscape with contour plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = solution_landscape_df['xcoord'].values\n",
    "y = solution_landscape_df['ycoord'].values\n",
    "codelength = solution_landscape_df['codelength'].values\n",
    "\n",
    "def plot_contour(x, y, codelength, resolution=200, contour_method='cubic'):\n",
    "    resolution = f\"{resolution}j\"\n",
    "    X, Y = np.mgrid[min(x):max(x):complex(resolution), min(y):max(y):complex(resolution)]\n",
    "    points = list(zip(x, y))\n",
    "    Z = griddata(points, codelength, (X, Y), method=contour_method)\n",
    "    return X, Y, Z\n",
    "\n",
    "X, Y, Z = plot_contour(x, y, codelength, resolution=200, contour_method='cubic')\n",
    "\n",
    "palette = sns.light_palette(\"navy\", reverse=True, as_cmap=True)\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5)\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.despine(f, left=True, bottom=True)\n",
    "p0 = ax.contourf(X, Y, Z, cmap=palette, alpha=0.5)\n",
    "#cbaxes = f.add_axes([0.8, 0.1, 0.03, 0.8])\n",
    "#cbar = f.colorbar(p0, cax=cbaxes)\n",
    "p1 = sns.scatterplot(x=\"xcoord\", y=\"ycoord\", hue=\"codelength\", size=\"clustersize\",\n",
    "            sizes=(50, 500), alpha=1, palette=palette, legend=\"full\",\n",
    "            data=solution_landscape_df)\n",
    "plt.axis('equal')\n",
    "plt.title(f'Solution landscape of {networkname} with partition distance {distance_threshold}')\n",
    "plt.xlabel('')\n",
    "#plt.xlabel('Embedded partition distance')\n",
    "plt.ylabel('')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "for handle in handles[Nclusters + 1:]:\n",
    "    handle.set_color(palette(0))\n",
    "labels[Nclusters + 1] = 'Cluster size'\n",
    "#handlestepsize = max(int((len(handles)-(Nclusters+1))/4),1)\n",
    "plt.legend([handles[Nclusters + 1], handles[Nclusters + 2], handles[-1]],\n",
    "           [labels[Nclusters + 1], labels[Nclusters + 2], labels[-1]],\n",
    "           bbox_to_anchor=(1.1, 1), loc='upper left', frameon=False, ncol=1, labelspacing=1.1)\n",
    "\n",
    "for clusterId in range(1, len(out) + 1):\n",
    "    p1.text(solution_landscape_df['xcoord'].iloc[clusterId - 1] + 0.07 * solution_landscape_df['clustersize'].iloc[clusterId - 1] / maxClusterSize + 0.05,\n",
    "            solution_landscape_df['ycoord'].iloc[clusterId - 1] - 0.1, \n",
    "            np.around(solution_landscape_df['codelength'].iloc[clusterId - 1], decimals=3),\n",
    "            horizontalalignment='left', \n",
    "            size='small',\n",
    "            color=palette(0),\n",
    "            weight='semibold')\n",
    "    p1.text(solution_landscape_df['xcoord'].iloc[clusterId - 1] + 0.07 *solution_landscape_df['clustersize'].iloc[clusterId - 1] / maxClusterSize + 0.05,\n",
    "            solution_landscape_df['ycoord'].iloc[clusterId - 1] + 0.05,\n",
    "            f\"{clusterId} ({solution_landscape_df['clustersize'].iloc[clusterId - 1]})\",\n",
    "            horizontalalignment='left', \n",
    "            size='small',\n",
    "            color=palette(0),\n",
    "            weight='semibold')\n",
    "\n",
    "plt.savefig(f\"output/solution_landscape_{networkname.split('.net')[0]}_d={distance_threshold}_a={accuracy}.png\",\n",
    "            bbox_inches=\"tight\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 1** Solution landscape. Circles represent partition clusters with size for the number of partitions in the cluster and color for the code length of the cluster center partition. Each cluster center is labeled by its number (ordered by increasing code length), the number of partitions it contains in parenthesis, and the code length of the cluster center partition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
